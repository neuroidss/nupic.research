{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and notebook statements\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "%load_ext line_profiler\n",
    "\n",
    "import torch\n",
    "from torch.nn.functional import conv2d, conv1d, relu_, sigmoid, hardtanh,  relu, unfold, fold, softmax\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "localConv=torch.nn.backends.thnn.backend.SpatialConvolutionLocal\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printgradnorm(self, grad_input, grad_output):\n",
    "    print('Inside class:' + self.__class__.__name__)\n",
    "    print('')\n",
    "    print('grad_input: ', type(grad_input))\n",
    "    print('grad_input[0]: ', type(grad_input[0]))\n",
    "    print('grad_output: ', type(grad_output))\n",
    "    print('grad_output[0]: ', type(grad_output[0]))\n",
    "    print('')\n",
    "    print('grad_input size:', grad_input[0].size())\n",
    "    print('grad_output size:', grad_output[0].size())\n",
    "    print('grad_input norm:', grad_input[0].norm())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kWinnerTakeAll(tensor, k):\n",
    "    values, indices = torch.topk(tensor, tensor.shape[-1] - k, largest=False, dim=-1)\n",
    "    new_tensor = tensor + 0\n",
    "    new_tensor[indices] = 0\n",
    "    return new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTrajectory(length, stepSize, width=1., directionStability=0.95, wrap=False, circular=False):\n",
    "    trajectory = np.zeros((int(length), 2))\n",
    "    turns = np.zeros((int(length)))\n",
    "    if circular:\n",
    "        r = np.sqrt(np.random.rand())*width\n",
    "        angle = np.random.rand()*2.*np.pi\n",
    "        x = np.cos(angle)*r\n",
    "        y = np.sin(angle)*r\n",
    "    else:\n",
    "        x = np.random.rand()*width\n",
    "        y = np.random.rand()*width\n",
    "    direction = np.random.rand() * 2 * np.pi\n",
    "    twopi = 2*np.pi\n",
    "    for i in range(int(length)):\n",
    "        oldDir = direction\n",
    "        recenter = 0\n",
    "        patience = 0\n",
    "        while True:\n",
    "            # This is a random value between (-180, +180) scaled by directionStability\n",
    "            dirChange = ((recenter + (np.random.rand() * twopi) - np.pi) *\n",
    "                       (1.0 - directionStability + patience))\n",
    "            direction = (direction + dirChange) % twopi\n",
    "            rotation = np.asarray([np.cos(direction), np.sin(direction)])\n",
    "            movement = stepSize*rotation\n",
    "            if circular:\n",
    "                position = (movement[0] + x)**2 + (movement[1] + y)**2\n",
    "                print(np.sqrt(position), width)\n",
    "                inBounds = np.sqrt(position) < width\n",
    "            else:\n",
    "                inBounds = 0 < (movement[0] + x) < width and 0 < (movement[1] + y) < width\n",
    "            if inBounds or wrap:\n",
    "                x += movement[0]\n",
    "                y += movement[1]\n",
    "                trajectory[i] = (x, y)\n",
    "                turns[i] = np.abs(oldDir - direction)\n",
    "                oldDir = direction\n",
    "                break\n",
    "            else:\n",
    "                patience += .5\n",
    "                recenter = oldDir\n",
    "                \n",
    "\n",
    "    return(trajectory, turns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L6L4Network(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 numL6=500,\n",
    "                 minicols=100,\n",
    "                 cellsPerMinicolumn=10,\n",
    "                 dendrites=1000,\n",
    "                 numGaussians=10,\n",
    "                 placeSigma=.01,\n",
    "                 envSize=1.,\n",
    "                 boostingAlpha=.01,\n",
    "                 circular=False,\n",
    "                 BCMLearningRate=.01,\n",
    "                 BCMAlpha=.1,\n",
    "                 SGDLearningRate=.01,\n",
    "                 L6Sparsity=.1,\n",
    "                 dendriteWeightSparsity=0.1,\n",
    "                 ):\n",
    "        \n",
    "        super(L6L4Network, self).__init__()\n",
    "        self.minicols = minicols\n",
    "        self.numL6 = numL6\n",
    "        self.cellsPerMinicolumn = cellsPerMinicolumn\n",
    "        self.numDendrites = dendrites\n",
    "        self.numGaussians = numGaussians\n",
    "        self.placeSigma=placeSigma\n",
    "        self.envSize = envSize\n",
    "        self.boostingAlpha = boostingAlpha\n",
    "        self.BCMLearningRate = BCMLearningRate\n",
    "        self.SGDLearningRate = SGDLearningRate\n",
    "        self.BCMAlpha = BCMAlpha\n",
    "        self.L6K = int(numL6*L6Sparsity)\n",
    "        self.L6DendriteK = int(dendriteWeightSparsity*minicols*cellsPerMinicolumn)\n",
    "        self.L4DendriteK = int(numL6*dendriteWeightSparsity)\n",
    "        \n",
    "        self.L6 = torch.nn.RNNCell(dendrites + 2, numL6)\n",
    "        if device == torch.device('cuda'):\n",
    "            self.L6 = self.L6.cuda()\n",
    "\n",
    "        self.L4DendriteWeights = torch.zeros((minicols*cellsPerMinicolumn, dendrites), device=device, dtype=torch.float, \n",
    "                                            requires_grad=True)\n",
    "        self.L4Dendrites = torch.zeros((dendrites, numL6), device=device, dtype=torch.float, \n",
    "                                      requires_grad=True)\n",
    "        \n",
    "        #self.L6DendriteWeights = torch.zeros((L6, dendrites), device=device, dtype=torch.float)\n",
    "        self.L6Dendrites = torch.zeros((dendrites, minicols*cellsPerMinicolumn), device=device, dtype=torch.float, \n",
    "                                      requires_grad=True)\n",
    "        \n",
    "        \n",
    "        torch.nn.init.kaiming_uniform_(self.L4Dendrites)\n",
    "        torch.nn.init.kaiming_uniform_(self.L6Dendrites)\n",
    "        torch.nn.init.kaiming_uniform_(self.L4DendriteWeights)\n",
    "        \n",
    "        self.zero = torch.zeros((1,), device=device, dtype=torch.float)\n",
    "        \n",
    "        \n",
    "        self.normalization = torch.nn.LayerNorm(numL6, elementwise_affine=False)\n",
    "        \n",
    "        if circular:\n",
    "            angles = np.random.rand(minicols, numGaussians)*2*np.pi\n",
    "            radii = np.sqrt(np.random.rand(minicols, numGaussians))*self.envSize\n",
    "            xComp = np.cos(angles)\n",
    "            yComp = np.sin(angles)\n",
    "            places = np.stack([xComp*radii, yComp*radii], axis=-1)\n",
    "            self.places = torch.tensor(places,\n",
    "                                       device=device,\n",
    "                                       dtype=torch.float,\n",
    "                                       requires_grad=False)\n",
    "        else:\n",
    "            self.places = torch.tensor(np.random.rand(minicols, numGaussians, 2)*self.envSize,\n",
    "                                       device=device,\n",
    "                                       dtype=torch.float,\n",
    "                                       requires_grad=False)\n",
    "        self.circular = circular\n",
    "        \n",
    "    def forward(self,\n",
    "                velocities,\n",
    "                feedforwards,\n",
    "                hidden,\n",
    "                L4,\n",
    "                L4DendriteHistory,\n",
    "                L6DendriteHistory,\n",
    "                L4History,\n",
    "                BCML4History):\n",
    "        \n",
    "        cost = torch.zeros((1,), device=device, dtype=torch.float)\n",
    "        for i in range(velocities.shape[0]):\n",
    "            vel = velocities[i]\n",
    "            feedforward = feedforwards[i]\n",
    "            L6DendriteActivations = kWinnerTakeAll(self.L6Dendrites, self.L6DendriteK)@(L4.view(L4.numel()))\n",
    "            relu_(L6DendriteActivations)\n",
    "            input = torch.cat((L6DendriteActivations, vel))\n",
    "            hidden = self.L6(input.view(1, input.numel()), hidden)\n",
    "            hidden = self.normalization(hidden)\n",
    "            hidden = kWinnerTakeAll(hidden, self.L6K)\n",
    "\n",
    "            L4DendriteActivations = kWinnerTakeAll(self.L4Dendrites, self.L4DendriteK)@(hidden.view(hidden.numel()))\n",
    "            #L4DendriteActivations = (L4DendriteActivations**2) + 1.\n",
    "            L4Predictions = (self.L4DendriteWeights@L4DendriteActivations).view(L4.shape)\n",
    "            L4Predictions = L4Predictions*(1 - (L4History + 0.01))\n",
    "            relu_(L4Predictions)\n",
    "            #plt.matshow(L4Predictions.detach().cpu().numpy()); plt.show()\n",
    "            L4Predictions = softmax(L4Predictions**2 + 1., dim = -1)\n",
    "            #plt.matshow(L4Predictions.detach().cpu().numpy()); plt.show()\n",
    "            L4 = feedforward[:, None]*L4Predictions\n",
    "\n",
    "            cost = cost + torch.sum(L4 ** 0.5) \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                L4History = L4Predictions*self.boostingAlpha + L4History*(1 - self.boostingAlpha)\n",
    "                BCML4History = (L4Predictions **2)*self.BCMAlpha + BCML4History*(1 - self.BCMAlpha)\n",
    "                L4DendriteHistory = (L4DendriteActivations**2)*self.BCMAlpha +\\\n",
    "                    L4DendriteHistory*(1 - self.BCMAlpha)\n",
    "                L6DendriteHistory = (L6DendriteActivations **2)*self.BCMAlpha +\\\n",
    "                    L6DendriteHistory*(1 - self.BCMAlpha)\n",
    "                \n",
    "                \n",
    "                if torch.isnan(hidden).any() or \\\n",
    "                    torch.isnan(L4).any() or \\\n",
    "                    torch.isnan(L4DendriteActivations).any(): \n",
    "                    import ipdb; ipdb.set_trace()\n",
    "                self.L4Dendrites = self.L4Dendrites +\\\n",
    "                    self.BCMLearningRate*self.BCMLearn(hidden, L4DendriteActivations, L4DendriteHistory)\n",
    "                self.L4DendriteWeights = self.L4DendriteWeights +\\\n",
    "                    self.BCMLearningRate*self.BCMLearn(L4DendriteActivations, L4.view(L4.numel()), BCML4History)\n",
    "                self.L6Dendrites = self.L6Dendrites +\\\n",
    "                    self.BCMLearningRate*self.BCMLearn(L4, L6DendriteActivations, L6DendriteHistory)\n",
    "\n",
    "                relu_(self.L4DendriteWeights)\n",
    "                relu_(self.L4Dendrites)\n",
    "        \n",
    "        return (torch.sum(cost),\n",
    "                hidden.detach(),\n",
    "                L4.detach(),\n",
    "                L4DendriteHistory.detach(),\n",
    "                L6DendriteHistory.detach(),\n",
    "                L4History.detach(),\n",
    "                BCML4History.detach())\n",
    "\n",
    "    \n",
    "    def BCMLearn(self, presyn, postsyn, history):\n",
    "        \"\"\"\n",
    "        Return: update\n",
    "        \"\"\"\n",
    "        postsyn = postsyn.view(postsyn.numel())\n",
    "        presyn = presyn.view(presyn.numel())\n",
    "        history = history.view(history.numel())\n",
    "        delta = torch.ger(postsyn*(postsyn - history), presyn)/(history[:, None] + 0.001)\n",
    "        \n",
    "        return (delta * self.BCMLearningRate)    \n",
    "    \n",
    "\n",
    "    def learn(self, runningTime, seqLen, speed, stability):\n",
    "        L4 = torch.zeros((self.minicols, self.cellsPerMinicolumn), device=device, dtype=torch.float,)\n",
    "        L4History = torch.zeros((self.minicols, self.cellsPerMinicolumn), device=device, dtype=torch.float,)\n",
    "        BCML4History = torch.zeros((self.minicols, self.cellsPerMinicolumn), device=device, dtype=torch.float)\n",
    "        L6History = torch.zeros((self.minicols, self.cellsPerMinicolumn), device=device, dtype=torch.float)\n",
    "        L4DendriteHistory = torch.zeros((self.numDendrites), device=device, dtype=torch.float)\n",
    "        L6DendriteHistory = torch.zeros((self.numDendrites), device=device, dtype=torch.float)\n",
    "        hidden = torch.zeros((1, self.numL6,), device=device, dtype=torch.float, requires_grad=True)\n",
    "        \n",
    "        \n",
    "        torch.nn.init.uniform_(L4)\n",
    "        torch.nn.init.uniform_(L4History)\n",
    "        torch.nn.init.uniform_(BCML4History)\n",
    "        torch.nn.init.uniform_(L6History)\n",
    "        torch.nn.init.uniform_(L4DendriteHistory)\n",
    "        torch.nn.init.uniform_(L6DendriteHistory)\n",
    "        torch.nn.init.uniform_(hidden)\n",
    "        \n",
    "        trajectory, turns = buildTrajectory(runningTime,\n",
    "                                            speed,\n",
    "                                            width=self.envSize,\n",
    "                                            wrap=False,\n",
    "                                            directionStability=stability,\n",
    "                                            circular=self.circular)\n",
    "        \n",
    "        velocities = torch.tensor(np.diff(trajectory, axis=0), device=device, dtype=torch.float,\n",
    "                                 requires_grad=False)\n",
    "        trajectory = torch.tensor(trajectory, device=device, dtype=torch.float,\n",
    "                                 requires_grad=False)\n",
    "        \n",
    "        cost = torch.zeros((1), device=device, dtype=torch.float, requires_grad=False)\n",
    "        for run in np.arange((runningTime - 1)/seqLen):\n",
    "            feedforwards = []\n",
    "            vels = []\n",
    "            \n",
    "            for t in range(seqLen):\n",
    "                i = int(t + run*seqLen)\n",
    "                pos = trajectory[i]\n",
    "                vel = velocities[i]\n",
    "\n",
    "                distances = torch.zeros((self.minicols,\n",
    "                                         self.numGaussians, 2),\n",
    "                                         device=device,\n",
    "                                         dtype=torch.float,\n",
    "                                         requires_grad=False)\n",
    "\n",
    "                distances[:, :, 0] = torch.abs(self.places[:, :, 0] - pos[0])\n",
    "                distances[:, :, 1] = torch.abs(self.places[:, :, 1] - pos[1])\n",
    "\n",
    "\n",
    "                activity = torch.exp(-1.*torch.norm(distances, 2, dim=-1)/(2*(self.placeSigma)))\n",
    "                activity = torch.sum(activity, dim=-1)\n",
    "                \n",
    "                feedforwards.append(activity)\n",
    "                vels.append(vel)\n",
    "                \n",
    "            vels = torch.stack((vels), dim=0)\n",
    "            feedforwards = torch.stack((feedforwards), dim=0)\n",
    "            \n",
    "            (cost,\n",
    "            hidden,\n",
    "            L4,\n",
    "            L4DendriteHistory,\n",
    "            L6DendriteHistory,\n",
    "            L4History,\n",
    "            BCML4History) = self.forward(vels,\n",
    "                            feedforwards,\n",
    "                            hidden,\n",
    "                            L4,\n",
    "                            L4DendriteHistory,\n",
    "                            L6DendriteHistory,\n",
    "                            L4History,\n",
    "                            BCML4History)  \n",
    "\n",
    "            print(run, cost.detach().cpu().numpy())\n",
    "            cost.backward()\n",
    "            with torch.no_grad():\n",
    "                for param in self.L6.parameters():\n",
    "                    if torch.isnan(self.SGDLearningRate*param.grad).any():\n",
    "                        print(\"NANs in gradient at {}!\".format(run))\n",
    "                        import ipdb; ipdb.set_trace()\n",
    "                    else:\n",
    "                        param -= self.SGDLearningRate*param.grad\n",
    "                    param.grad.zero_()\n",
    "            velocities=velocities.detach()\n",
    "            trajectory=trajectory.detach()\n",
    "            self.places=self.places.detach()\n",
    "            hidden = hidden.detach()\n",
    "            L4 = L4.detach()\n",
    "            L4DendriteHistory = L4DendriteHistory.detach()\n",
    "            L6DendriteHistory = L6DendriteHistory.detach()\n",
    "            BCML4History = BCML4History.detach()\n",
    "            cost = cost.detach()\n",
    "            self.L4DendriteWeights = self.L4DendriteWeights.detach()\n",
    "            self.L4Dendrites = self.L4Dendrites.detach()\n",
    "            self.L6Dendrites = self.L6Dendrites.detach() \n",
    "        return(L4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (4) : unspecified launch failure at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524543037166\\work\\aten\\src\\thc\\generic/THCTensorCopy.c:20",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ec142001db30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m                  \u001b[0mSGDLearningRate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                  \u001b[0mL6Sparsity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                  \u001b[0mdendriteWeightSparsity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                  )\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-5a4315e5cdb1>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, numL6, minicols, cellsPerMinicolumn, dendrites, numGaussians, placeSigma, envSize, boostingAlpha, circular, BCMLearningRate, BCMAlpha, SGDLearningRate, L6Sparsity, dendriteWeightSparsity)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRNNCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdendrites\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumL6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL6\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         self.L4DendriteWeights = torch.zeros((minicols*cellsPerMinicolumn, dendrites), device=device, dtype=torch.float, \n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mcuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    247\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    180\u001b[0m                 \u001b[1;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m                 \u001b[1;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m                 \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    247\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cuda runtime error (4) : unspecified launch failure at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524543037166\\work\\aten\\src\\thc\\generic/THCTensorCopy.c:20"
     ]
    }
   ],
   "source": [
    "net = L6L4Network(\n",
    "                 numL6=100,\n",
    "                 minicols=100,\n",
    "                 cellsPerMinicolumn=10,\n",
    "                 dendrites=100,\n",
    "                 numGaussians=10,\n",
    "                 placeSigma=.05,\n",
    "                 envSize=1.,\n",
    "                 boostingAlpha=.05,\n",
    "                 circular=False,\n",
    "                 BCMLearningRate=.001,\n",
    "                 BCMAlpha=.1,\n",
    "                 SGDLearningRate=.0001,\n",
    "                 L6Sparsity=.5,\n",
    "                 dendriteWeightSparsity=.5,\n",
    "                 )\n",
    "\n",
    "places = net.places.view(net.minicols*net.numGaussians, 2)\n",
    "plt.figure()\n",
    "plt.scatter(places[:, 0], places[:, 1])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "trajectory, turns = buildTrajectory(50,\n",
    "                                    .01,\n",
    "                                    width=net.envSize,\n",
    "                                    wrap=False,\n",
    "                                    directionStability=.95,\n",
    "                                    circular=net.circular)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(trajectory[:, 0], trajectory[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "#    print(i*5)\n",
    "    result = net.learn(100, 5, .01, .95)\n",
    "#    print(torch.mean(net.L4Dendrites).cpu().numpy())\n",
    "#     print(torch.mean(net.L4DendriteWeights).cpu().numpy())\n",
    "#     print(torch.mean(net.L6Dendrites).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(net.L4Dendrites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
