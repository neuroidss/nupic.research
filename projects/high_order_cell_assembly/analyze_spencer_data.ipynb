{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This file is to analyze the spencer data and generate figures by calling\n",
    "# source codes\n",
    "import numpy as np\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_response_mat(spiketrain, imgPara, stimType, goodCells, plotRaster):\n",
    "    \n",
    "    numNeuron = len(goodCells) # the number of neurons\n",
    "    print numNeuron\n",
    "    \n",
    "    # imgPara.stim_time = 32s, imgPara.dt = 0.075103, \n",
    "    # numFramesPerStim is the number of the frames within 32s movie stimulus\n",
    "    \n",
    "    numFramesPerStim = int(round(imgPara['stim_time'] / imgPara['dt']))\n",
    "    # print numFramesPerStim\n",
    "    spikeMat = []\n",
    "    ## generate the spike timing for all the neurons through all trials\n",
    "    for rep in range(imgPara['stimrep']):    \n",
    "        spikesCurrentTrial = np.zeros((numNeuron, numFramesPerStim))\n",
    "        spikesRaster = []\n",
    "        cellI = 0\n",
    "        for i in range(len(goodCells)):\n",
    "            # spikesI: spiking timing of a specific neuron at a specific trial\n",
    "            # print i\n",
    "            spikesI = spiketrain[0,i][0][rep,stimType]\n",
    "            # print spikesI\n",
    "            spikesI = np.round(spikesI[np.nonzero(spikesI<=numFramesPerStim)])\n",
    "            #print spikesI\n",
    "            spikesI = spikesI[np.nonzero(spikesI>0)];\n",
    "            spikesI = spikesI.astype(int)\n",
    "            \n",
    "            spikesI = spikesI - 1\n",
    "            # print spikesI\n",
    "            # along the 426 frames, spike timings was labeled\n",
    "            spikesCurrentTrial[cellI,spikesI] = 1\n",
    "            cellI  = cellI +1;\n",
    "            spikesRaster.append(spikesI*imgPara['dt'] -1)\n",
    "        \n",
    "\n",
    "        # return spikeMat as the spiking time for all neurons\n",
    "        spikeMat.append(spikesCurrentTrial)  \n",
    "    \n",
    "    # change spikeMat to be numpy array\n",
    "    spikeMat = np.array(spikeMat)   \n",
    "    print spikeMat.shape\n",
    "    return spikeMat\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_sparsity_over_trials(spikeMat, imgPara):\n",
    "    print spikeMat.shape\n",
    "    stimrep = int(imgPara['stimrep'])\n",
    "    sparsity = np.zeros((stimrep,1))\n",
    "    numFramesPerStim = int(round(imgPara['stim_time']/imgPara['dt']))\n",
    "    # the returned sparsity is everaged for all the neurons' \n",
    "    # firings within each specific trial\n",
    "    for rep in range(stimrep):\n",
    "        numFramesArray = np.array(range(numFramesPerStim))\n",
    "        spikesCurrentTrial = spikeMat[rep]  \n",
    "        sparsity[rep] = np.mean(spikesCurrentTrial) # average by columns and by rows    \n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function code has to be debugged further with matrix dimension matching\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "def calculate_subset_index(spikeMat, numFramesPerStim):\n",
    "    numNeuron = spikeMat.shape[1]\n",
    "    numFrames = spikeMat.shape[2]\n",
    "    numRpts = spikeMat.shape[0] \n",
    "    \n",
    "    spikeEarly = np.zeros(numNeuron, numFramesPerStim)\n",
    "    \n",
    "    # spikeEarly only count the spikes in the first trial\n",
    "    spikeEarly = spikeMat[0]\n",
    "    \n",
    "    timewindow = 1\n",
    "    \n",
    "    sharedNeuronsAll = np.zeros(4)\n",
    "    numNeuronsLateAll = np.zeros(4)\n",
    "    tt = 0\n",
    "    \n",
    "    for rep in range(17,21): # compute trials from 17 to 20\n",
    "        spikeLate = spikeMat[rep]\n",
    "        spikeLate = signal.convolve2d(spikeLate, np.ones((1, timewindow)),'same')\n",
    "        spikesLate[np.nonzero(spikesLate>0)] = 1\n",
    "        # find all the cells both fire both at the 1st trial and the last trial\n",
    "        sharedNeurons= numpy.multiply(spikeEarly, spikeLate).sum(axis=0)\n",
    "        numNeuronLate = spikeLate.sum(axis=0)\n",
    "        \n",
    "        sharedNeuronsAll[tt] = sharedNeurons.sum()\n",
    "        numNeuronsLateAll[tt] = numNeuronsLate.sum()\n",
    "        tt = tt+1\n",
    "    \n",
    "    # calculate the subsetindex for trials from 17 to 20, the last 4 trials    \n",
    "    subsetIndex = sharedNeuronsAll.sum()/numNeuronsLateAll.sum()\n",
    "    return subsetIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function code has to be debugged further with matrix dimension matching\n",
    "def generate_poisson_spikes(spikeMat, imgPara):\n",
    "    meanFiringRate = np.mean(spikeMat, 1)\n",
    "    numNeuron = spikeMat.shape[1]\n",
    "    NT = spikeMat.shape[2]\n",
    "    # NT is number of frames through 20 trials\n",
    "    poissSpikes = np.zeros(numNeuron, NT)\n",
    "    for i in range(numNeuron):\n",
    "        poissSpikes[i,:] = np.random.poisson(meanFiringRate[i], (1, NT))\n",
    "    return poissSpikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function code has to be debugged further with matrix dimension matching\n",
    "def shuffle_spikes(spikeMat, imgPara):\n",
    "    [numNeuron, NT]= spikeMat.shape\n",
    "    fakeSpikes = np.zeros(numNeuron, NT)\n",
    "    numFramesPerStim = int(round(imgPara['stim_time'] / imgPara['dt']))\n",
    "    \n",
    "    for i in range(numNeuron):\n",
    "        spikeR = spikeTrains[i,:].reshape((numFramesPerStim, imgPara['stimrep']))\n",
    "        shuffleSpikes = np.zeros(numFramesPerStim, imgPara['stimrep'])\n",
    "        for t in range(numFramesPerStim):\n",
    "            # shuffle the spikeMat among 20 trials\n",
    "            shuffleSpikes[t, :] = spikeR[t, np.random.permutation(imgPara['stimrep'])]\n",
    "        # generate the fake-shuffled spikes for each specific neuron\n",
    "        fakeSpikes[i, :] = shuffleSpikes.reshape(( 1, NT))\n",
    "    \n",
    "    return fakeSpikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function code has to be debugged further with matrix dimension matching\n",
    "from itertools import combinations\n",
    "\n",
    "def synchrony_analysis_efficient(spikeMat, numCoactive):\n",
    "    minRpts = 1\n",
    "\n",
    "    #numSteps is the total number of frames through all 20 trials\n",
    "    [numNeurons, numSteps] = spikeMat.shape\n",
    "    popRate = spikeMat.sum(axis=0) # sum all the spike numbers across rows\n",
    "\n",
    "    binaryWords = []\n",
    "    frequency = []\n",
    "    for t in range(numSteps): # numSteps = 20*426 = 8520\n",
    "   \n",
    "        if popRate[t] >= numCoactive: # match requirement of coactive number of neurons\n",
    "            activeCells = np.nonzeros(spikeMat[:,t]>0) # return the indices of the neurons firing at time t \n",
    "\n",
    "            # enumerate all permutations\n",
    "            c = combinations(range(activeCells), numCoactive) # return all the possible combinations of fired cell assembly\n",
    "            if numCoactive > 1:\n",
    "                binaryWords.append(c)\n",
    "            \n",
    "\n",
    "    # frequency returns the counts of firings of cell assembly together through 20 trials\n",
    "    frequency = np.zeros((len(binaryWords),1))  # of cell assembly by 1 \n",
    "    for i in range(len(binaryWords)):\n",
    "        frequency[i] = np.nonzeros(spikeMat[binaryWords[i,:],:].sum()>=numCoactive).sum()\n",
    "\n",
    "    ## merge\n",
    "    idx= np.nonzeros(frequency==1) \n",
    "    binaryWordsNew = binaryWords[idx, :]\n",
    "    frequencyNew = frequency[idx]\n",
    "    \n",
    "    for numRpts in range(2, max(frequency)):\n",
    "        idx= np.nonzeros(frequency==numRpts)\n",
    "        spikePatterns = binaryWords[idx,:]\n",
    "        \n",
    "        uniqueSpikes = np.zeros((len(idx),numCoactive))\n",
    "        k=1 # the next two for loops is to remove duplicates from spikePattern\n",
    "     \n",
    "        for i in range(len(spikePatterns)):\n",
    "            presence = 0\n",
    "            for j in range(k):\n",
    "                if max(abs(spikePatterns[i,:]-uniqueSpikes[j,:]))==0:\n",
    "                    presence = 1\n",
    "                    break\n",
    "            if presence ==0:\n",
    "                uniqueSpikes[k,:] = spikePatterns[i,:]\n",
    "                k = k + 1\n",
    "       \n",
    "        \n",
    "        uniqueSpikes = uniqueSpikes[1:k-1,:]\n",
    "    \n",
    "        binaryWordsNew.append(uniqueSpikes)\n",
    "        frequencyNew.append(np.ones((len(uniqueSpikes),1))*numRpts)\n",
    " \n",
    "    # returned frequency is the firing frequency for each cell assembly\n",
    "    # returned binaryWords is the corresponding cell indices of cell assembly\n",
    "    frequency = frequencyNew\n",
    "    binaryWords = binaryWordsNew\n",
    "\n",
    "    idx = np.nonzeros(frequency>=minRpts)\n",
    "    frequency = frequency[idx]\n",
    "    binaryWords = binaryWords[idx,:]\n",
    "    \n",
    "    return frequency, binaryWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function code has to be debugged further with matrix dimension matching\n",
    "def calculate_occurance_time(frequency, numFramesPerStim, spikeMat, binaryWords, numCoactive):\n",
    "    \n",
    "\n",
    "    # check occurence of high-order patterns\n",
    "    idx = np.nonzeros(frequency >=2) # the frequency of spikings\n",
    "    \n",
    "    timeInMovieSTD = np.zeros((idx.shape[0],1))\n",
    "\n",
    "    binEdges = range(-20,21)\n",
    "    timeJitterDistribution = np.zeros((1, len(binEdges)))\n",
    "\n",
    "    trialDist = []\n",
    "\n",
    "    interval = []\n",
    "    timeAll = []\n",
    "\n",
    "    timeInMovieDist = np.zeros(numFramesPerStim, 1)\n",
    "    occurance_time = np.zeros(len(frequency), 1)\n",
    "    \n",
    "    for i in range(len(idx)): # search through the neurons that fired at least twice\n",
    "        # find out the time points when there are at least numCoactive neurons firing together\n",
    "        times = np.nonzeros(spikeMat[binaryWords[i,:],:].sum()>=numCoactive)\n",
    "        \n",
    "        # kl: find out which the exact time frame the cell assembly respond to\n",
    "        timeInMovie = times % numFramesPerStim\n",
    "        # kl: the response at 0 is assumed to be responding to the last movie frame\n",
    "        timeInMovie[timeInMovie==0] = numFramesPerStim\n",
    "        # distribution of the time points when coactive firing\n",
    "        timeInMovieDist[timeInMovie] = timeInMovieDist[timeInMovie]+1\n",
    "        # what trials includes the coactive firings\n",
    "        trial = (times-timeInMovie)/numFramesPerStim + 1\n",
    "        # average the time points of coactive firings for all the frequency\n",
    "        occurance_time[idx[i]] = np.mean(timeInMovie)\n",
    "        # histogram of the coactive firings around average time points within binEdges\n",
    "        counts = np.histogram(timeInMovie-np.mean(timeInMovie), range=binEdges)\n",
    "        # normalize counts\n",
    "        if counts.sum()>1 : \n",
    "            counts = counts/counts.sum()\n",
    "        \n",
    "        # the histogram of distribution of firing time points of coactive assembly around average time points\n",
    "        timeJitterDistribution = timeJitterDistribution + counts\n",
    "        timeInMovieSTD[i] = np.std(timeInMovie)\n",
    "\n",
    "   \n",
    "    # the histogram of distribution of firing time points of coactive assembly around average time points\n",
    "    timeJitterDistribution = timeJitterDistribution/len(idx)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the general code for draw pictures for spencer's data\n",
    "\n",
    "# Combo3_V1andAL.mat includes all the 5 recordings of calcium imaging data\n",
    "# within V1 and AL recorded simultaneously.\n",
    "data = sio.loadmat(\"./data/2016-10-26_1/Combo3_V1.mat\")\n",
    "data_c = data['data']\n",
    "\n",
    "# analyze the 3rd data, and spiketrain recorded from V1\n",
    "data_c = data['data']\n",
    "# imgPara\n",
    "imgPara = data_c[0][0][1]\n",
    "print imgPara\n",
    "stim_type = imgPara['stim_type']\n",
    "stim_time = imgPara['stim_time']\n",
    "updatefr = imgPara['updatefr']\n",
    "intertime = imgPara['intertime']\n",
    "stimrep = imgPara['stimrep']\n",
    "dt = imgPara['dt']\n",
    "F = imgPara['F']\n",
    "F_gray = imgPara['F_gray']\n",
    "# spiketrain\n",
    "spiketrain = data_c[0][0][2]\n",
    "# number of neurons\n",
    "numNeuron = spiketrain.shape[1]\n",
    "numFramesPerStim = int(round(stim_time / dt))\n",
    "\n",
    "spikesPerNeuron = np.zeros((numNeuron,3))\n",
    "for i in range(numNeuron):\n",
    "    for j in range(stim_type):\n",
    "        numSpike = 0\n",
    "        for rep in range(stimrep):\n",
    "            spikesI = spiketrain[0,i][0][rep,j]\n",
    "            numSpike = numSpike + len(spikesI[0]);\n",
    "\n",
    "        spikesPerNeuron[i, j] = numSpike;\n",
    "\n",
    "# print spikesPerNeuron\n",
    "print \"Number of cells: %d\" % numNeuron\n",
    "# Population Response to Natural Stimuli\n",
    " # goodCells = range(numNeuron); # choose all the cells to be goodCells\n",
    "goodCells = np.nonzero(spikesPerNeuron[:,stimType]>3)\n",
    "print goodCells[0].shape\n",
    "spikeMat = get_response_mat(spiketrain, imgPara, stimType,goodCells[0], 0);\n",
    "\n",
    "# show sparsity over trials\n",
    "sparsity = calculate_sparsity_over_trials(spikeMat, imgPara)\n",
    "# sparsity plot figure(1)\n",
    "plt.plot(sparsity,'k')\n",
    "plt.xlabel('trial #')\n",
    "plt.ylabel('sparseness')\n",
    "plt.show()\n",
    "\n",
    "# subset analysis, an array of numbers trial 17 to 20\n",
    "subsetIndex = calculate_subset_index(spikeMat, numFramesPerStim);\n",
    "\n",
    "# generate Poisson spike trains\n",
    "subsetIndexShuffleList = []\n",
    "subsetIndexPoissonList=[]\n",
    "for rep in range(20):\n",
    "    # generate Poisson spike trains \n",
    "    poissSpikes = generate_poisson_spikes(spikeMat, imgPara)\n",
    "    # generate shuffled spike trains\n",
    "    shuffledSpikes = shuffle_spikes(spikeMat, imgPara);\n",
    "    \n",
    "    subsetIndexShuffle = calculate_subset_index(shuffledSpikes, numFramesPerStim)\n",
    "    subsetIndexPoisson = calculate_subset_index(poissSpikes, numFramesPerStim)\n",
    "    subsetIndexPoissonList.append(subsetIndexPoisson)\n",
    "    subsetIndexShuffleList.append(subsetIndexShuffle)\n",
    "    \n",
    "# from here, begin to analyze the cell assembly result   \n",
    "numCoactive = 3   # 3 cell assembly\n",
    "[frequency, binaryWords] = synchrony_analysis_efficient(spikeMat, numCoactive)\n",
    "[binEdges, timeJitterDistribution3, timeInMovieDist3] = calculate_occurance_time(...\n",
    "    frequency, numFramesPerStim, spikeMat, binaryWords, numCoactive);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
